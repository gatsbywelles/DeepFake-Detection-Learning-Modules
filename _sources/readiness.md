# Module 2: Readiness

## Risk Assessment Checklist for Deepfake & Social Engineering Threats 
As the prevalence of AI-manipulated information increases, companies face a more complex range of dangers. Deepfake assaults present unique challenges for both technological defenses and human perception because they could modify audio, video, or images. According to a 2023 study by Awodiji et al., attackers commonly employ cognitive biases, social trust, and organizational procedures to conduct deception or fraud campaigns. Kshetri and Voas (2025) propose a systematic risk assessment that considers risks along several dimensions, such as likelihood, possible impact, and human susceptibility. 

A comprehensive list of items should include: 
+ **Asset classification:** Identify the people, information, and systems that are most likely to be targeted, such as CEOs, finance divisions, or media outlets. 
+ **Threat vector analysis:** Monitor the methods and intricacy of potential assaults, including phishing emails, voice impersonation, and fake media. 
+ **Impact assessment:** Determine the potential financial, reputational, operational, and legal fallout from successful assaults. 
+ **Vulnerability mapping:** Assess organizational and technical shortcomings, such as outdated detection technologies, insufficient monitoring protocols, or low employee awareness. 
+ **Combine Human and Technical Vulnerability Mapping:** According to Awodiji et al. (2023) and Kshetri and Voas (2025), attackers exploit both technical mistakes and cognitive biases. A distinct component of the risk assessment should be the use of simulated assaults to evaluate employee susceptibility.

Examine staff training, familiarity with social engineering tactics, and influence vulnerability while evaluating human factors. By combining these components, organizations can proactively prioritize defense methods, resource allocation, and event response plans. 

## Governance Model 
Being prepared for deepfake risks requires effective governance. Several studies have shown that no department can handle AI-driven hazards on its own (Evans et al., 2021). Teams from IT, legal, HR, and compliance must work together to create a thorough governance framework. These cross-functional committees ensure that risk assessment, policy creation, and incident response are all coordinated and in line with corporate goals. 

```{raw} html
<style>
.video-container{position:relative;padding-bottom:56.25%;height:0;overflow:hidden}
.video-container iframe{position:absolute;top:0;left:0;width:100%;height:100%}
</style>
<div class="video-container">
  <iframe
    src="https://youtu.be/3qy-ITKkNxM"
    title="Descriptive video title"
    loading="lazy"
    frameborder="0"
    allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture; web-share"
    allowfullscreen
    referrerpolicy="strict-origin-when-cross-origin">
  </iframe>
</div>
